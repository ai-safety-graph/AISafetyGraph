# Network Modularity

## Summary
 Network modularity in neural networks refers to the presence of distinct groups of neurons (modules) that exhibit strong internal connectivity but weak external connectivity. Recent research has shown that trained and pruned neural networks, particularly multi-layer perceptrons (MLPs), often display a surprising degree of modularity. This modular structure becomes even more pronounced when networks are trained using dropout techniques. The presence of modularity in neural networks is significant because it can potentially enhance the interpretability of these systems, allowing researchers and engineers to better understand their internal workings. Studying the importance and interdependencies of these modules can provide insights into network performance and functionality. This emerging field of research aims to uncover and quantify the inherent structural organization within neural networks, which may have implications for improving network design, efficiency, and explainability in artificial intelligence systems.
## Research Papers

- [[Pruned Neural Networks are Surprisingly Modular]]
