# Question Answering

## Summary
 Question Answering (QA) is a crucial task in natural language processing that tests the ability of AI systems to understand and reason about text. Recent research has focused on developing more challenging datasets and techniques to improve QA performance. These include unsupervised question decomposition methods to break down complex multi-hop questions into simpler sub-questions, as demonstrated in the ONUS algorithm. Additionally, datasets like LogiQA and ConTRoL have been introduced to specifically test logical reasoning capabilities in QA systems. These datasets involve complex reasoning types and are derived from expert-written questions, making them significantly more challenging than previous benchmarks. Despite advancements in deep learning techniques, state-of-the-art models still struggle with these more complex reasoning tasks, performing far below human levels. These developments highlight the ongoing challenges in AI alignment research, particularly in bridging the gap between machine and human-level reasoning in question answering tasks.
## Research Papers

- [[Unsupervised Question Decomposition for Question Answering]]
- [[LogiQA A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning]]
- [[Natural Language Inference in Context -- Investigating Contextual Reasoning over Long Texts]]
