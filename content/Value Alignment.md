# Value Alignment

## Sub-topics

- [[Defining Human Values]]
- [[Inverse Reinforcement Learning]]
- [[Imitation Learning]]
- [[Societal Value Alignment]]
- [[Decision Theory]]
- [[Agent Reward Management]]
- [[Intrinsic Motivation]]
- [[Reward Learning]]
- [[Low Impact AI]]
- [[Friend-Foe Modeling]]
- [[Consequences of Misalignment]]
- [[Learning from Human Feedback]]
- [[Exploration in Reinforcement Learning]]
- [[Empathic AI]]
- [[Moral Uncertainty]]
- [[Metric Optimization]]
- [[Algorithmic Fairness]]
- [[AI Debate]]
- [[AI Truthfulness]]
- [[Artificial Stupidity]]
- [[Interactive Explanations]]
- [[Cooperative AI]]
- [[Bounded Rationality]]
- [[Value Alignment Verification]]
- [[Trust in AI Systems]]
