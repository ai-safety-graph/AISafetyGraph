# Artificial Stupidity

## Summary
 Artificial Stupidity is an emerging concept in AI alignment research that proposes deliberately introducing limitations to artificial intelligence systems to make them safer and more controllable. This approach involves constraining an AI's capabilities to match or approximate human-level performance in specific tasks, rather than allowing it to achieve superhuman abilities. The implementation of Artificial Stupidity can involve limiting an AI's computing power, memory capacity, or deliberately introducing inefficiencies in certain cognitive processes. By aligning AI capabilities more closely with human intellectual limits, researchers aim to create Artificial General Intelligence (AGI) systems that are more predictable, manageable, and less likely to pose existential risks. This strategy represents a novel approach to addressing safety concerns in advanced AI development, focusing on controlled limitations rather than unrestricted capability expansion.
## Research Papers

- [[Building Safer AGI by introducing Artificial Stupidity]]
